{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test sequencial ok.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhTteDneQZ+bf/VpHIMdvc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardoleandrodev/aprendizadodemaquina01/blob/main/test_sequencial_ok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR29AOrljXFK"
      },
      "source": [
        "from numpy import loadtxt\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from keras.layers import Dense\n",
        "from pandas import read_csv as rc,factorize as fc,to_numeric as tnum,set_option as op"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUAC25ao1LvB"
      },
      "source": [
        "def getUniqueNumber(seq):\n",
        "    s = 0\n",
        "    for i,q in enumerate(seq):\n",
        "      s+=(q**(q+i))\n",
        "    return s"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D0J2Lp_jn9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eeca7af-c9fb-417f-e2be-b9a5e826d024"
      },
      "source": [
        "from random import randint as ri\n",
        "data=[]\n",
        "for k in range(1,100000):\n",
        "  nm = [ri(0,2) for k in range(6)]\n",
        "  #if not nm in data:\n",
        "  data.append(nm)\n",
        "\n",
        "res = []\n",
        "for d in data:\n",
        "  res.append(getUniqueNumber(d))\n",
        "\n",
        "resuniq = np.unique(res)\n",
        "tamres = len(np.unique(res))\n",
        "print(data[:10])\n",
        "print(res[:10])\n",
        "resuniq"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 1, 2, 2, 2, 0], [0, 0, 2, 2, 1, 2], [2, 0, 1, 1, 0, 0], [0, 1, 1, 0, 1, 2], [2, 1, 1, 2, 0, 2], [2, 1, 2, 0, 2, 1], [0, 1, 1, 1, 0, 0], [2, 2, 0, 1, 0, 0], [1, 0, 1, 1, 1, 0], [0, 0, 1, 1, 1, 1]]\n",
            "[114, 178, 6, 132, 166, 86, 4, 13, 4, 5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "        27,  28,  29,  30,  31,  33,  34,  35,  36,  37,  38,  39,  40,\n",
              "        41,  42,  43,  44,  45,  46,  47,  49,  50,  51,  52,  53,  54,\n",
              "        55,  57,  58,  59,  60,  61,  62,  65,  66,  67,  68,  69,  70,\n",
              "        71,  72,  73,  74,  75,  76,  77,  78,  79,  81,  82,  83,  84,\n",
              "        85,  86,  87,  89,  90,  91,  92,  93,  94,  97,  98,  99, 100,\n",
              "       101, 102, 103, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116,\n",
              "       117, 118, 121, 122, 124, 125, 129, 130, 131, 132, 133, 134, 135,\n",
              "       136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 149,\n",
              "       150, 151, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165,\n",
              "       166, 167, 169, 170, 171, 172, 173, 174, 177, 178, 179, 180, 181,\n",
              "       182, 185, 186, 188, 189, 193, 194, 195, 196, 197, 198, 199, 201,\n",
              "       202, 203, 204, 205, 206, 209, 210, 211, 212, 213, 214, 217, 218,\n",
              "       220, 221, 225, 226, 227, 228, 229, 230, 233, 234, 236, 237, 241,\n",
              "       242, 244, 245, 249, 252])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84hQaRtNlI93"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "val_treino,val_teste,val_res_treino,val_res_teste = train_test_split(data,res,test_size=0.1,train_size=0.5)\n",
        "\n",
        "#val_treino = np.array(val_treino)\n",
        "#val_teste = np.array(val_teste)\n",
        "#val_res_treino = np.array(val_res_treino)\n",
        "#val_res_teste = np.array(val_res_teste)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKBlZpyMLOIN"
      },
      "source": [
        "MODELO NOMINAL\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm3aO7ldlSBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed81e89f-4e2d-466f-df29-435f77bac731"
      },
      "source": [
        "# definir o modelo com keras\n",
        "model = MultinomialNB()\n",
        "model.fit(val_treino, val_res_treino)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjKl4fpfPHVe"
      },
      "source": [
        "Modelo Sequencial SOFTMAX(varias saidas)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0IpNb8ePL3w"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "X = np.array(val_treino)\n",
        "Y  = np.array(val_res_treino)\n",
        "\n",
        "def baseline_model():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(20, input_dim=len(X[0]), activation='relu'))\n",
        "  model.add(Dense(20,  activation='relu'))\n",
        "  #model.add(Dense(20,  activation='relu'))\n",
        "  model.add(Dense(len(resuniq), activation='softmax'))\n",
        "  # Compile model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=30, batch_size=10,use_multiprocessing=True, verbose=1)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09gIGcfO41cf"
      },
      "source": [
        "TREINAMENTO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q40fnn80SJy",
        "outputId": "e7071b5c-8f1f-477a-daed-07a9ade5411d"
      },
      "source": [
        "estimator.fit(X,Y)\n",
        "#estimator.save('/content/random_seq_len4.h5')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "5000/5000 [==============================] - 21s 1ms/step - loss: 2.9637 - accuracy: 0.3089\n",
            "Epoch 2/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.6539 - accuracy: 0.8097\n",
            "Epoch 3/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.3264 - accuracy: 0.9080\n",
            "Epoch 4/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.1782 - accuracy: 0.9527\n",
            "Epoch 5/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.1009 - accuracy: 0.9762\n",
            "Epoch 6/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0545 - accuracy: 0.9891\n",
            "Epoch 7/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0347 - accuracy: 0.9936\n",
            "Epoch 8/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0215 - accuracy: 0.9956\n",
            "Epoch 9/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0179 - accuracy: 0.9964\n",
            "Epoch 10/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0324 - accuracy: 0.9924\n",
            "Epoch 11/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0049 - accuracy: 0.9992\n",
            "Epoch 12/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0016 - accuracy: 0.9999\n",
            "Epoch 13/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0064 - accuracy: 0.9985\n",
            "Epoch 14/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0261 - accuracy: 0.9936\n",
            "Epoch 15/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0128 - accuracy: 0.9970\n",
            "Epoch 16/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0087 - accuracy: 0.9979\n",
            "Epoch 17/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0081 - accuracy: 0.9979\n",
            "Epoch 18/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0087 - accuracy: 0.9979\n",
            "Epoch 19/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0115 - accuracy: 0.9969\n",
            "Epoch 20/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0032 - accuracy: 0.9993\n",
            "Epoch 21/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 2.3602e-04 - accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0049 - accuracy: 0.9989\n",
            "Epoch 23/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 1.7207e-04 - accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0110 - accuracy: 0.9977\n",
            "Epoch 25/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 1.0390e-04 - accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0392 - accuracy: 0.9913\n",
            "Epoch 27/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0018 - accuracy: 0.9996\n",
            "Epoch 28/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 1.4297e-04 - accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0067 - accuracy: 0.9986\n",
            "Epoch 30/30\n",
            "5000/5000 [==============================] - 7s 1ms/step - loss: 7.2996e-04 - accuracy: 0.9998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4f75f25090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYMcrhUJ4vJ3"
      },
      "source": [
        "VERIFICA PORCENTAGEM DE ACERTO(ACURÁCIA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNZiB4zoZjAP",
        "outputId": "6c41d2ef-9dff-4979-9b1b-f1bebc62f488"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "pred = estimator.predict(val_teste)\n",
        "accuracy = accuracy_score(val_res_teste, pred)\n",
        "mt = confusion_matrix(val_res_teste, pred)\n",
        "print(mt,f'\\nacuracia de {accuracy*100} %\\n')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 1s 928us/step\n",
            "[[ 31   0   0 ...   0   0   0]\n",
            " [  0 135   0 ...   0   0   0]\n",
            " [  0   0 304 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...  17   0   0]\n",
            " [  0   0   0 ...   0  32   0]\n",
            " [  0   0   0 ...   0   0  14]] \n",
            "acuracia de 99.76 %\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbpi0yse4pw0"
      },
      "source": [
        "VERIFICA ACERTOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSZ8uG5m4f3d",
        "outputId": "1067ca1f-a42a-4b7d-b7bc-3685c50dd62e"
      },
      "source": [
        "import random as rn\n",
        "nm = rn.randint(1,len(X))\n",
        "confer = X[nm:nm+10]\n",
        "confer = [[1,2,2,2,1,2]]\n",
        "pred = estimator.predict(confer)\n",
        "\n",
        "for i,prd in enumerate(pred):\n",
        "  if list(confer[i]) == data[res.index(prd)]:\n",
        "    print(f'acertou! =D Proc:{list(confer[i])} Encontrado:{data[res.index(prd)]} ValorRes:{getUniqueNumber(data[res.index(prd)])} ValorPred:{getUniqueNumber(confer[i])} Index:{res.index(prd)} Id:{prd}')\n",
        "  else:\n",
        "    print(f'errou   =(( Proc:{list(confer[i])} Encontrado:{data[res.index(prd)]} ValorRes:{getUniqueNumber(data[res.index(prd)])} ValorPred:{getUniqueNumber(confer[i])} Index:{res.index(prd)} Id:{prd}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n",
            "errou   =(( Proc:[1, 2, 2, 2, 1, 2] Encontrado:[0, 2, 2, 2, 1, 2] ValorRes:186 ValorPred:186 Index:74 Id:186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TMiaEKXL85H"
      },
      "source": [
        "Modelo Sequencial sigmoid\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1vwdsFHlkou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081092b8-d9e0-43d6-9060-448bb446a795"
      },
      "source": [
        "# definir o modelo com keras\n",
        "# inicializar o modelo sequencial\n",
        "\n",
        "#model = MultinomialNB()\n",
        "model = Sequential()\n",
        "# inicializar a primeira camada, com 12 neurÃ´nios, 8 entradas utilizando a funÃ§Ã£o ReLU\n",
        "model.add(Dense(5, input_dim=len(val_treino[0]), activation='relu'))\n",
        "#model.add(Dense(10, activation='relu'))\n",
        "#model.add(Dense(5, activation='sigmoid'))\n",
        "# inicializar a Ãºltima camada (camada de saÃ­da) com um neurÃ´nio e a funÃ§Ã£o Sigmoid/softmax\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(val_treino, val_res_treino, epochs=100, batch_size=15,use_multiprocessing=False,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 19.4849 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 19.3599 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 19.2350 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 19.1102 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.9855 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.8609 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 18.7365 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 18.6100 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 18.4803 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 18.3506 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 18.2208 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.0910 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 17.9613 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 17.8315 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 17.7017 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 17.5720 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 17.4424 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 17.3128 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 17.1833 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 17.0538 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.9245 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.7952 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.6659 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.5368 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.4078 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 16.2788 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 16.1500 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.0212 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 15.8925 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.7639 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 15.6354 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 15.5070 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 15.3787 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.2505 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 15.1223 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 14.9943 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 14.8663 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.7385 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.6107 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.4830 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.3554 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.2279 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 14.1005 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.9731 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 13.8459 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.7187 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 13.5916 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.4646 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.3376 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.2108 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.0840 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.9573 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.8307 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.7041 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.5777 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.4512 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.3249 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.1986 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.0724 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.9463 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.8202 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.6943 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.5683 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.4424 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.3166 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.1847 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.0445 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.9029 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.7602 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.6164 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.4716 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.3261 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.1800 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.0332 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.8859 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7381 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.5899 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.4414 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.2926 - accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1435 - accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9941 - accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.8446 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6949 - accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5450 - accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.3949 - accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.2448 - accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.0945 - accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.9441 - accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7936 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6430 - accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.4924 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.3416 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1908 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0399 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8890 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7380 - accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5869 - accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4358 - accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2846 - accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.1334 - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f00770e6850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fPd6ZE8lzUK",
        "outputId": "d646f9c1-338e-485f-a4c1-0f0d6a714dea"
      },
      "source": [
        "\n",
        "#predictions = model.predict(val_teste)\n",
        "#from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "#accuracy = accuracy_score(val_res_teste, predictions)\n",
        "#mt = confusion_matrix(val_res_teste, predictions)\n",
        "#print(mt,f'acuracia de {accuracy*100} %')\n",
        "pred = model.predict([[2,2,2,1]])\n",
        "\n",
        "#res.index(pred),res[res.index(pred)],data[res.index(pred)],getUniqueNumber(res.index(pred)),pred\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    }
  ]
}